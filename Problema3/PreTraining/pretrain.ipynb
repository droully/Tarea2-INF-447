{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un uso alternativo de los AE es el \"pre-training\" no supervisado de redes profundas, esto es hacer un AE que parta de una capa, vaya a si misma, y pase por la siguiente. Esto logra inicializar los pesos de la red de mejor forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se hara una red clasica de 2 capas con funcion sigmoid con la que se comparara la pre-entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "NVAL=5000\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "x_val=x_train[:NVAL]\n",
    "x_train=x_train[NVAL:]\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "Y_val=Y_train[:NVAL]\n",
    "Y_train=Y_train[NVAL:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6519 - val_loss: 14.7190\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s - loss: 14.6566 - val_loss: 14.7190\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=SGD(lr=1.0), loss='categorical_crossentropy')\n",
    "histog=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/Sigmoid/768x1000x1000x10-NFT-50epochs.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se entrena un AE para encontrar los pesos de la primera capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "  700/55000 [..............................] - ETA: 7s - loss: 0.3199 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s - loss: 0.1433 - val_loss: 0.1041\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0948 - val_loss: 0.0880\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0844 - val_loss: 0.0815\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0796 - val_loss: 0.0780\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0766 - val_loss: 0.0757\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0747 - val_loss: 0.0741\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0733 - val_loss: 0.0729\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0722 - val_loss: 0.0719\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0713 - val_loss: 0.0712\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0706 - val_loss: 0.0706\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0700 - val_loss: 0.0701\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0695 - val_loss: 0.0696\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0691 - val_loss: 0.0692\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0687 - val_loss: 0.0689\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0684 - val_loss: 0.0686\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0681 - val_loss: 0.0683\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0679 - val_loss: 0.0681\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0676 - val_loss: 0.0679\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0674 - val_loss: 0.0677\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0672 - val_loss: 0.0675\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0671 - val_loss: 0.0674\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0669 - val_loss: 0.0672\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0668 - val_loss: 0.0671\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0666 - val_loss: 0.0669\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0665 - val_loss: 0.0668\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0664 - val_loss: 0.0667\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0663 - val_loss: 0.0666\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0662 - val_loss: 0.0665\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0661 - val_loss: 0.0664\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s - loss: 0.0660 - val_loss: 0.0663\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(1000,activation='sigmoid')(input_img1)\n",
    "decoded1 = Dense(784, activation='sigmoid')(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=SGD(lr=1.0,momentum=0.9, nesterov=True), loss='binary_crossentropy')\n",
    "autoencoder1.fit(x_train, x_train, nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('AE/Sigmoid/autoencoder_layer1.h5')\n",
    "encoder1.save('AE/Sigmoid/encoder_layer1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro AE para la segunda capa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "\r",
      "   25/55000 [..............................] - ETA: 108s - loss: 0.7245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s - loss: 0.6266 - val_loss: 0.5973\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5894 - val_loss: 0.5843\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5817 - val_loss: 0.5799\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5787 - val_loss: 0.5779\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5771 - val_loss: 0.5767\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5762 - val_loss: 0.5760\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5756 - val_loss: 0.5754\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5751 - val_loss: 0.5751\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5748 - val_loss: 0.5748\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5745 - val_loss: 0.5746\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5743 - val_loss: 0.5744\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5742 - val_loss: 0.5743\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5740 - val_loss: 0.5741\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5739 - val_loss: 0.5740\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5738 - val_loss: 0.5739\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5737 - val_loss: 0.5739\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5737 - val_loss: 0.5738\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5736 - val_loss: 0.5737\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5735 - val_loss: 0.5737\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5735 - val_loss: 0.5736\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5734 - val_loss: 0.5735\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5733 - val_loss: 0.5735\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5733 - val_loss: 0.5735\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5733 - val_loss: 0.5734\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5732 - val_loss: 0.5734\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5732 - val_loss: 0.5734\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5732 - val_loss: 0.5733\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5731 - val_loss: 0.5733\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5731 - val_loss: 0.5733\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5731 - val_loss: 0.5732\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5730 - val_loss: 0.5732\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5730 - val_loss: 0.5732\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5730 - val_loss: 0.5732\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5730 - val_loss: 0.5732\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5730 - val_loss: 0.5731\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5731\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5731\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5731\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5731\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5731\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5729 - val_loss: 0.5730\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5730\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5728 - val_loss: 0.5729\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 4s - loss: 0.5727 - val_loss: 0.5729\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded1 = encoder1.predict(x_train)\n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(1000,))\n",
    "encoded2 = Dense(1000, activation='sigmoid')(input_img2)\n",
    "decoded2 = Dense(1000, activation='sigmoid')(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=SGD(lr=1.0,momentum=0.9, nesterov=True), loss='binary_crossentropy')\n",
    "autoencoder2.fit(x_train_encoded1,x_train_encoded1,nb_epoch=30,batch_size=25,\n",
    "shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "autoencoder2.save('AE/Sigmoid/autoencoder_layer2.h5')\n",
    "encoder2.save('AE/Sigmoid/encoder_layer2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace el \"fine tuning\" de la red con los pesos obtenidos con los autoencoders, esto hace que la red \"parta con ventaja\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.3811 - acc: 0.9611 - val_loss: 0.3754 - val_acc: 0.9691\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.3618 - acc: 0.9699 - val_loss: 0.3706 - val_acc: 0.9710\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.3434 - acc: 0.9732 - val_loss: 0.1899 - val_acc: 0.9825\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1924 - acc: 0.9833 - val_loss: 0.1847 - val_acc: 0.9843\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1894 - acc: 0.9844 - val_loss: 0.1832 - val_acc: 0.9845\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1876 - acc: 0.9851 - val_loss: 0.1820 - val_acc: 0.9850\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1862 - acc: 0.9857 - val_loss: 0.1817 - val_acc: 0.9853\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1851 - acc: 0.9861 - val_loss: 0.1812 - val_acc: 0.9855\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1844 - acc: 0.9864 - val_loss: 0.1805 - val_acc: 0.9857\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1837 - acc: 0.9867 - val_loss: 0.1805 - val_acc: 0.9857\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1830 - acc: 0.9870 - val_loss: 0.1800 - val_acc: 0.9857\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1825 - acc: 0.9872 - val_loss: 0.1795 - val_acc: 0.9859\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1820 - acc: 0.9874 - val_loss: 0.1795 - val_acc: 0.9859\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1816 - acc: 0.9876 - val_loss: 0.1795 - val_acc: 0.9860\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1813 - acc: 0.9877 - val_loss: 0.1797 - val_acc: 0.9857\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1809 - acc: 0.9878 - val_loss: 0.1794 - val_acc: 0.9859\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1806 - acc: 0.9880 - val_loss: 0.1791 - val_acc: 0.9862\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1803 - acc: 0.9880 - val_loss: 0.1789 - val_acc: 0.9862\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1801 - acc: 0.9882 - val_loss: 0.1790 - val_acc: 0.9861\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1799 - acc: 0.9883 - val_loss: 0.1788 - val_acc: 0.9862\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.1797 - acc: 0.9884 - val_loss: 0.1789 - val_acc: 0.9863\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0125 - val_acc: 0.9959\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0120 - val_acc: 0.9962\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0119 - val_acc: 0.9960\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0113 - val_acc: 0.9963\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0110 - val_acc: 0.9964\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0110 - val_acc: 0.9964\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0109 - val_acc: 0.9964\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0106 - val_acc: 0.9966\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0105 - val_acc: 0.9966\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0103 - val_acc: 0.9966\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0105 - val_acc: 0.9965\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0102 - val_acc: 0.9968\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0103 - val_acc: 0.9965\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0105 - val_acc: 0.9965\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0105 - val_acc: 0.9966\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0103 - val_acc: 0.9966\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0101 - val_acc: 0.9968\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0016 - acc: 0.9998 - val_loss: 0.0103 - val_acc: 0.9968\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0103 - val_acc: 0.9965\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0103 - val_acc: 0.9967\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0105 - val_acc: 0.9967\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0105 - val_acc: 0.9966\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 5s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0105 - val_acc: 0.9968\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 5s - loss: 9.6726e-04 - acc: 0.9999 - val_loss: 0.0105 - val_acc: 0.9968\n"
     ]
    }
   ],
   "source": [
    "autoencoder1=load_model('AE/Sigmoid/autoencoder_layer1.h5')\n",
    "autoencoder2=load_model('AE/Sigmoid/autoencoder_layer2.h5')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='sigmoid', input_shape=(784,)))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Dense(1000, activation='sigmoid'))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[1].get_weights())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=SGD(lr=1.0),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "histft=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/Sigmoid/768x1000x1000x10-finetunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABzihEbUm3cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1f42aca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histog.history['val_loss'])\n",
    "plt.plot(histft.history['val_loss'])\n",
    "plt.title('model loss sigmoid 30 epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss original', 'loss pretrained'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene el resultado esperado, que la red pre-entrenada tenga mejores resultados antes, sin embargo, esta ventaja se pierde para una cantidad suficiente de epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repetira la actividad anterior pero con funciones de activacion Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.0682 - val_loss: 0.1285\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.1094 - val_loss: 0.0974\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0724 - val_loss: 0.0770\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0539 - val_loss: 0.0759\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0423 - val_loss: 0.0679\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0342 - val_loss: 0.0652\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0280 - val_loss: 0.0629\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0230 - val_loss: 0.0590\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0196 - val_loss: 0.0636\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0168 - val_loss: 0.0601\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0146 - val_loss: 0.0578\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0126 - val_loss: 0.0578\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0111 - val_loss: 0.0563\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0099 - val_loss: 0.0572\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0087 - val_loss: 0.0572\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0079 - val_loss: 0.0572\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0072 - val_loss: 0.0561\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0065 - val_loss: 0.0557\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0060 - val_loss: 0.0573\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0055 - val_loss: 0.0568\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0051 - val_loss: 0.0574\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0047 - val_loss: 0.0573\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0044 - val_loss: 0.0570\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0042 - val_loss: 0.0574\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0039 - val_loss: 0.0577\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0037 - val_loss: 0.0572\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0035 - val_loss: 0.0571\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0033 - val_loss: 0.0579\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0031 - val_loss: 0.0572\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0030 - val_loss: 0.0587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='tanh', input_shape=(784,)))\n",
    "model.add(Dense(1000, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='Adagrad',loss='categorical_crossentropy')\n",
    "histog=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/Tanh/768x1000x1000x10-NFT-50epochs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s - loss: 4.7814 - val_loss: 1.2171e-05\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s - loss: 1.2215e-05 - val_loss: 1.2171e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(1000,activation='tanh')(input_img1)\n",
    "decoded1 = Dense(784, activation='tanh')(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer=SGD(lr=1.0,momentum=0.9, nesterov=True), loss='categorical_crossentropy')\n",
    "autoencoder1.fit(x_train, x_train, nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('AE/Tanh/autoencoder_layer1.h5')\n",
    "encoder1.save('AE/Tanh/encoder_layer1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "\r",
      "   25/55000 [..............................] - ETA: 141s - loss: 0.7900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 4s - loss: -5.2329 - val_loss: -5.2302\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2408 - val_loss: -5.2303\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2403 - val_loss: -5.2292\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2397 - val_loss: -5.2292\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2394 - val_loss: -5.2285\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2391 - val_loss: -5.2279\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2381 - val_loss: -5.2261\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2369 - val_loss: -5.2261\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2369 - val_loss: -5.2261\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2369 - val_loss: -5.2260\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2369 - val_loss: -5.2261\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2494 - val_loss: -5.2418\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2518 - val_loss: -5.2411\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2518 - val_loss: -5.2397\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2507 - val_loss: -5.2392\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2501 - val_loss: -5.2391\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2501 - val_loss: -5.2392\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2501 - val_loss: -5.2392\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2501 - val_loss: -5.2392\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2501 - val_loss: -5.2391\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2503 - val_loss: -5.2396\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2507 - val_loss: -5.2399\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2504 - val_loss: -5.2393\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2503 - val_loss: -5.2394\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2502 - val_loss: -5.2387\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2486 - val_loss: -5.2362\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2473 - val_loss: -5.2363\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2473 - val_loss: -5.2362\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2473 - val_loss: -5.2362\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s - loss: -5.2473 - val_loss: -5.2362\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded1 = encoder1.predict(x_train)\n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(1000,))\n",
    "encoded2 = Dense(1000, activation='tanh')(input_img2)\n",
    "decoded2 = Dense(1000, activation='tanh')(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer=SGD(lr=1.0,momentum=0.9, nesterov=True), loss='categorical_crossentropy')\n",
    "autoencoder2.fit(x_train_encoded1,x_train_encoded1,nb_epoch=30,batch_size=25,\n",
    "shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "autoencoder2.save('AE/Tanh/autoencoder_layer2.h5')\n",
    "encoder2.save('AE/Tanh/encoder_layer2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.6845 - acc: 0.5088 - val_loss: 6.2761 - val_acc: 0.5962\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.4325 - acc: 0.5891 - val_loss: 6.2575 - val_acc: 0.6004\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.4154 - acc: 0.5938 - val_loss: 6.2441 - val_acc: 0.6032\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.4061 - acc: 0.5964 - val_loss: 6.2399 - val_acc: 0.6048\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3994 - acc: 0.5982 - val_loss: 6.2376 - val_acc: 0.6044\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3952 - acc: 0.5997 - val_loss: 6.2341 - val_acc: 0.6062\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3919 - acc: 0.6006 - val_loss: 6.2351 - val_acc: 0.6052\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3896 - acc: 0.6011 - val_loss: 6.2312 - val_acc: 0.6060\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3875 - acc: 0.6017 - val_loss: 6.2316 - val_acc: 0.6048\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3859 - acc: 0.6021 - val_loss: 6.2298 - val_acc: 0.6062\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3843 - acc: 0.6026 - val_loss: 6.2300 - val_acc: 0.6060\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3833 - acc: 0.6029 - val_loss: 6.2291 - val_acc: 0.6062\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3822 - acc: 0.6032 - val_loss: 6.2291 - val_acc: 0.6060\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3816 - acc: 0.6033 - val_loss: 6.2291 - val_acc: 0.6066\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3810 - acc: 0.6035 - val_loss: 6.2290 - val_acc: 0.6070\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3805 - acc: 0.6038 - val_loss: 6.2288 - val_acc: 0.6066\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3800 - acc: 0.6038 - val_loss: 6.2283 - val_acc: 0.6064\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3796 - acc: 0.6039 - val_loss: 6.2278 - val_acc: 0.6070\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3793 - acc: 0.6040 - val_loss: 6.2275 - val_acc: 0.6066\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3790 - acc: 0.6040 - val_loss: 6.2280 - val_acc: 0.6074\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3788 - acc: 0.6040 - val_loss: 6.2280 - val_acc: 0.6072\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3785 - acc: 0.6041 - val_loss: 6.2277 - val_acc: 0.6072\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3783 - acc: 0.6041 - val_loss: 6.2279 - val_acc: 0.6074\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3781 - acc: 0.6042 - val_loss: 6.2280 - val_acc: 0.6072\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3780 - acc: 0.6043 - val_loss: 6.2284 - val_acc: 0.6072\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3778 - acc: 0.6042 - val_loss: 6.2275 - val_acc: 0.6074\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3777 - acc: 0.6043 - val_loss: 6.2282 - val_acc: 0.6078\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3776 - acc: 0.6043 - val_loss: 6.2280 - val_acc: 0.6072\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3775 - acc: 0.6043 - val_loss: 6.2278 - val_acc: 0.6082\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3774 - acc: 0.6043 - val_loss: 6.2278 - val_acc: 0.6082\n"
     ]
    }
   ],
   "source": [
    "autoencoder1=load_model('AE/Tanh/autoencoder_layer1.h5')\n",
    "autoencoder2=load_model('AE/Tanh/autoencoder_layer2.h5')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='tanh', input_shape=(784,)))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Dense(1000, activation='tanh'))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[1].get_weights())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='Adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "histft=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/Sigmoid/768x1000x1000x10-finetunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ae16e3c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histog.history['val_loss'])\n",
    "plt.plot(histft.history['val_loss'])\n",
    "plt.title('model loss Tanh 30 epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss original', 'loss pretrained'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red con funcion de activacion Tanh preentrenada parte mejor que la inicializada con valores aleatorios, sin embargo, llega a un minimo local peor que la original. Se repitio el experimiento multiples veces y siempre se llegaba a un resultado del mismo tipo, puede que el azar sea la causa, ya que es extraño que por tan solo cambiar la funcion de activacion el preentrenamiento parta en un minimo local, en especial ya que la sigmoide es un tipo de Tanh.\n",
    "\n",
    "Tambien se utilizo el optimizador Adagrad, ya que SGD no convergia nunca, e incluso partia peor.\n",
    "\n",
    "\n",
    "Extrañamente el AE de la segunda capa empezo a arrojar error negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite lo anterior pero con ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.1749 - val_loss: 0.0842\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0546 - val_loss: 0.0664\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0306 - val_loss: 0.0566\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0177 - val_loss: 0.0608\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0105 - val_loss: 0.0610\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0064 - val_loss: 0.0567\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0038 - val_loss: 0.0594\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0026 - val_loss: 0.0594\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0019 - val_loss: 0.0603\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0015 - val_loss: 0.0614\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0012 - val_loss: 0.0618\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0011 - val_loss: 0.0625\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s - loss: 9.6335e-04 - val_loss: 0.0636\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s - loss: 8.7709e-04 - val_loss: 0.0636\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s - loss: 8.0188e-04 - val_loss: 0.0642\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s - loss: 7.4962e-04 - val_loss: 0.0650\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s - loss: 7.0280e-04 - val_loss: 0.0654\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.6274e-04 - val_loss: 0.0662\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.3188e-04 - val_loss: 0.0664\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.0466e-04 - val_loss: 0.0669\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.7882e-04 - val_loss: 0.0669\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.5786e-04 - val_loss: 0.0676\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.4001e-04 - val_loss: 0.0678\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.2269e-04 - val_loss: 0.0685\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.0867e-04 - val_loss: 0.0684\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.9449e-04 - val_loss: 0.0686\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.8261e-04 - val_loss: 0.0688\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.7226e-04 - val_loss: 0.0696\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.6213e-04 - val_loss: 0.0698\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.5293e-04 - val_loss: 0.0698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='Adagrad',loss='categorical_crossentropy')\n",
    "histog=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/relu/768x1000x1000x10-NFT-50epochs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.1621 - val_loss: 0.1210\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.1156 - val_loss: 0.1121\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.1092 - val_loss: 0.1062\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.1035 - val_loss: 0.1036\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.1020 - val_loss: 0.1031\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0998 - val_loss: 0.0990\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0982 - val_loss: 0.0982\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0982 - val_loss: 0.0967\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0965 - val_loss: 0.0976\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0962 - val_loss: 0.0972\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0960 - val_loss: 0.0975\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0950 - val_loss: 0.0991\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0943 - val_loss: 0.0944\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0943 - val_loss: 0.0982\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0941 - val_loss: 0.0952\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0942 - val_loss: 0.0945\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0939 - val_loss: 0.0936\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0937 - val_loss: 0.0940\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0938 - val_loss: 0.0933\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0935 - val_loss: 0.0940\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0940 - val_loss: 0.0973\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0935 - val_loss: 0.0948\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0935 - val_loss: 0.0938\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0938 - val_loss: 0.0922\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0935 - val_loss: 0.0933\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0933 - val_loss: 0.0934\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0934 - val_loss: 0.0979\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0940 - val_loss: 0.0992\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0951\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0939 - val_loss: 0.0931\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0942 - val_loss: 0.0920\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0943 - val_loss: 0.0942\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0943 - val_loss: 0.0957\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0931\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0946 - val_loss: 0.0936\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0946\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0944 - val_loss: 0.0972\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0940 - val_loss: 0.0931\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0944 - val_loss: 0.0923\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0947 - val_loss: 0.0936\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0936 - val_loss: 0.0935\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0938 - val_loss: 0.0942\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0943 - val_loss: 0.0934\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0944 - val_loss: 0.0933\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0937 - val_loss: 0.0957\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0935 - val_loss: 0.1014\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_img1 = Input(shape=(784,))\n",
    "encoded1 = Dense(1000,activation='relu')(input_img1)\n",
    "decoded1 = Dense(784, activation='relu')(encoded1)\n",
    "autoencoder1 = Model(input=input_img1, output=decoded1)\n",
    "encoder1 = Model(input=input_img1, output=encoded1)\n",
    "autoencoder1.compile(optimizer='Adadelta', loss='binary_crossentropy')\n",
    "autoencoder1.fit(x_train, x_train, nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, x_val))\n",
    "autoencoder1.save('AE/relu/autoencoder_layer1.h5')\n",
    "encoder1.save('AE/relu/encoder_layer1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.2047 - val_loss: 0.1400\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0919 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0145 - val_loss: 0.0216\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0091 - val_loss: 0.0129\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0059 - val_loss: 0.0131\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0044 - val_loss: 0.0083\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================] - 7s - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0011 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0086 - val_loss: -0.0097\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0148 - val_loss: -0.0085\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0150 - val_loss: -0.0088\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0155 - val_loss: -0.0094\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0160 - val_loss: -0.0085\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0161 - val_loss: -0.0113\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0180 - val_loss: -0.0128\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0178 - val_loss: -0.0140\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0184 - val_loss: -0.0139\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0189 - val_loss: -0.0150\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0190 - val_loss: -0.0154\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0217 - val_loss: -0.0196\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0230 - val_loss: -0.0159\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0229 - val_loss: -0.0183\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0239 - val_loss: -0.0191\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0239 - val_loss: -0.0157\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0237 - val_loss: -0.0211\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0241 - val_loss: -0.0163\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0238 - val_loss: -0.0200\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0246 - val_loss: -0.0194\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0261 - val_loss: -0.0201\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0264 - val_loss: -0.0223\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0259 - val_loss: -0.0169\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0265 - val_loss: -0.0208\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0283 - val_loss: -0.0213\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0284 - val_loss: -0.0207\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0290 - val_loss: -0.0232\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0292 - val_loss: -0.0229\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0289 - val_loss: -0.0169\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0289 - val_loss: -0.0228\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0289 - val_loss: -0.0236\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0289 - val_loss: -0.0226\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0290 - val_loss: -0.0210\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0286 - val_loss: -0.0212\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0288 - val_loss: -0.0214\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0287 - val_loss: -0.0198\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0286 - val_loss: -0.0192\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0286 - val_loss: -0.0221\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================] - 7s - loss: -0.0284 - val_loss: -0.0202\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0281 - val_loss: -0.0208\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================] - 6s - loss: -0.0282 - val_loss: -0.0212\n"
     ]
    }
   ],
   "source": [
    "x_train_encoded1 = encoder1.predict(x_train)\n",
    "x_val_encoded1 = encoder1.predict(x_val)\n",
    "x_test_encoded1 = encoder1.predict(x_test)\n",
    "\n",
    "input_img2 = Input(shape=(1000,))\n",
    "encoded2 = Dense(1000, activation='relu')(input_img2)\n",
    "decoded2 = Dense(1000, activation='relu')(encoded2)\n",
    "autoencoder2 = Model(input=input_img2, output=decoded2)\n",
    "encoder2 = Model(input=input_img2, output=encoded2)\n",
    "autoencoder2.compile(optimizer='Adadelta', loss='binary_crossentropy')\n",
    "autoencoder2.fit(x_train_encoded1,x_train_encoded1,nb_epoch=30,batch_size=25,\n",
    "shuffle=True, validation_data=(x_val_encoded1, x_val_encoded1))\n",
    "autoencoder2.save('AE/relu/autoencoder_layer2.h5')\n",
    "encoder2.save('AE/relu/encoder_layer2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 1000)              785000    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 1,796,010\n",
      "Trainable params: 1,796,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.1754 - acc: 0.9463 - val_loss: 0.0858 - val_acc: 0.9742\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0640 - acc: 0.9804 - val_loss: 0.0664 - val_acc: 0.9788\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0379 - acc: 0.9890 - val_loss: 0.0618 - val_acc: 0.9810\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0242 - acc: 0.9931 - val_loss: 0.0545 - val_acc: 0.9820\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0156 - acc: 0.9962 - val_loss: 0.0604 - val_acc: 0.9826\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0588 - val_acc: 0.9838\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0564 - val_acc: 0.9834\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0569 - val_acc: 0.9836\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0033 - acc: 0.9997 - val_loss: 0.0580 - val_acc: 0.9840\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0586 - val_acc: 0.9838\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0607 - val_acc: 0.9830\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9836\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 5s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9840\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 5s - loss: 9.5278e-04 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9842\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 5s - loss: 8.1209e-04 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9838\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 5s - loss: 7.0321e-04 - acc: 1.0000 - val_loss: 0.0627 - val_acc: 0.9842\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 5s - loss: 6.2416e-04 - acc: 1.0000 - val_loss: 0.0636 - val_acc: 0.9842\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.5678e-04 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 0.9844\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s - loss: 5.0315e-04 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9840\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.5395e-04 - acc: 1.0000 - val_loss: 0.0650 - val_acc: 0.9844\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 5s - loss: 4.1354e-04 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 0.9840\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 5s - loss: 3.7850e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9846\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s - loss: 3.4762e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9842\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 5s - loss: 3.2134e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9842\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.9780e-04 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 0.9844\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.7577e-04 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9842\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.5710e-04 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 0.9844\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.3957e-04 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9846\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.2289e-04 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9844\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s - loss: 2.0999e-04 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9842\n"
     ]
    }
   ],
   "source": [
    "autoencoder1=load_model('AE/relu/autoencoder_layer1.h5')\n",
    "autoencoder2=load_model('AE/relu/autoencoder_layer2.h5')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, activation='relu', input_shape=(784,)))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[1].get_weights())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='Adagrad',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "histft=model.fit(x_train, Y_train,nb_epoch=30, batch_size=25,\n",
    "shuffle=True, validation_data=(x_val, Y_val))\n",
    "model.save('AE/relu/768x1000x1000x10-finetunned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVHLfwAhqsWat6+fjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ae742a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histog.history['val_loss'])\n",
    "plt.plot(histft.history['val_loss'])\n",
    "plt.title('model loss relu 30 epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss original', 'loss pretrained'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dos redes partieron relativamente iguales para luego overfittear y el error empezar a diverger, a pesar de que la red preentrenada diverga mas rapido, es poco probable que se deba a la inicializacion, ya que eso solo tiene efecto al principio del entrenamiento.\n",
    "\n",
    "Este mismo comportamiento se vio para distintas combinaciones de optimizadores tanto en los AE como en las propias redes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
